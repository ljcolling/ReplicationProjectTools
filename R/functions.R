#' Generates two vectors, one called LabNames and one called Nodes
#' These contain the lab names and node codes for the replication project
#' @export
GetLabNames <- function() {
  LabNames <<-
    c(
      "Corballis",
      "Chen",
      "Mammarella",
      "Treccani",
      #"Javier",
      "Ortiz-Ouellet-Lupiáñez-Santiago",
      "Lukavský",
      "Lindemann",
      "Cipora",
      "Mieth",
      "Hancock",
      "Toomarian",
      "Holmes",
      "Ocampo",
      #"Goffin",
      "Ansari",
      "Bryce",
      #"Colling",
      "Colling (Szűcs)",
      "Moeller"
    )
  Nodes <<-
    c(
      "yu8hp",
      "vzt3a",
      "8gdp3",
      "ecdmw",
      "xmyd9",
      "6ea38",
      "xb6t2",
      "fkjbz",
      "t5y2h",
      "2t9re",
      "encwv",
      "pqcf4",
      "kx4w9",
      "kwg95",
      "5hgk4",
      "3s4uh",
      "nzxwr"
    )
}


#' Generates my osf token
#' @export
MyOSFToken <- function() {
  return("#")
}

#' Gets all the files that belong to a particular node
#' @export
GetNodeFiles <- function(dataFolder, this.node) {
  this.path = paste0(dataFolder, this.node)
  this.files = paste0(this.path, "/", dir(path = this.path, pattern = "*"))
  this.file = this.files[(grepl(".edf", this.files) == FALSE)]
  return(this.file)
}

#' ReadMatFile is a wrapper function for the readMat from the R.matlab package.
#' It's adds basic error checking. This is implemented by checking that it is a
#' MATLAB 5.0 MAT file. All files generated by the Fischer replication should be
#' of this format. If the file type is incorrect then a NULL is returned
#' @export
ReadMatFile<-function(filename){

  if(file.exists(filename) == FALSE){
    cat('!!!!', filename, 'IS MISSING!!!')
    cat('\n')
    return(NULL)
  }

  header = rawToChar(readBin(filename,"raw",19))

  if((header == 'MATLAB 5.0 MAT-file') == FALSE){
    cat('Unexpected file format! Ignoring file!')
    cat('\n')
    return(NULL)
  }


  matcontents = R.matlab::readMat(filename)

  return(matcontents)
}

#' text padding for the forest plots
#' @export
as.padded.text <-function(x, pad.length = 7){
  if(is.na(x) == FALSE){
    as.text = sprintf("%2.2f",x)
    times = pad.length - str_length(as.text)
    pad = paste0(rep(' ',times),collapse = '')
    as.text = glue("{pad}{as.text}")
    return(as.text)
  } else {
    return(NA)
  }
}


#' GetAllNodeFile downloads all the files from a particular node. It stores the
#' files in subfolder /data/{nodename} in the current working folder. This only
#' downloads .xls and .mat files, and does not download the .edf files which are
#' not needed for the analysis
#' @export
GetAllNodeFiles <- function(node) {
  GetFileListFromNode <- function(node) {
    token = ReplicationProjectTools::MyOSFToken()
    page = 1
    url = glue::glue('https://api.osf.io/v2/nodes/{node}/files/osfstorage/?page={page}')

    web.content = httr::GET(url, add_headers(Authorization = paste("Bearer", token)))
    web.content.parsed = jsonlite::fromJSON(content(web.content, 'text', encoding = "UTF-8"))

    pagesToGet = ceiling(web.content.parsed$links$meta$total / web.content.parsed$links$meta$per_page)

    GetFilesFromOSF <- function(this.url, token) {
      this.page = httr::GET(this.url, add_headers(Authorization = paste("Bearer", token)))
      this.page.parsed = jsonlite::fromJSON(content(this.page, 'text', encoding = "UTF-8"))
      this.names = this.page.parsed$data$attributes$name
      this.links = this.page.parsed$data$links$download

      return(tibble::tibble(
        names = this.names,
        links = this.links,
        node = node
      ))

    }

    files = lapply(1:pagesToGet, function(x)
      GetFilesFromOSF(
        glue(
          'https://api.osf.io/v2/nodes/{node}/files/osfstorage/?page={x}'
        ),
        token
      ))

    return(Reduce(function(x, y)
      rbind(x, y), files))
  }

  this.nodeFiles = GetFileListFromNode(node)
  this.nodeFiles = this.nodeFiles[which((this.nodeFiles %>% pull(names) %>% grepl(pattern = ".edf")) == FALSE),]

  dataFolder = file.path(getwd(), "data")

  DownloadFileFromNode <- function(name, link, node, dataFolder) {
    token = ReplicationProjectTools::MyOSFToken()
    bin.content <-
      httr::GET(link, add_headers(Authorization = paste("Bearer", token)))
    filename = glue::glue('{dataFolder}/{node}/{name}')
    file.obj = file(filename, "wb")
    writeBin(object = content(bin.content, "raw"), con = file.obj)
    close(file.obj)
    msg = glue('{name} downloaded ok from {node}!')
    cat(msg)
    cat("\n")
    return(msg)
  }

  system(paste("mkdir ", paste0(dataFolder, "/", node)))
  pmap(
    list(
      this.nodeFiles$names,
      this.nodeFiles$links,
      this.nodeFiles$node,
      dataFolder
    ),
    DownloadFileFromNode
  )
}





#' Re-write level 2 names
#' jsjs
#' @export
Lvl2ReWrite<-function(x){
  case_when(x == "RH" ~ "Right handed",
            x == "LH" ~ "Left handed",
            x == "LS" ~ "Left hand finger counting",
            x == "RS" ~ "Right hand finger counting",
            x == "LTR" ~ "Exclusively left-to-right readers/writers",
            x == "NLR" ~ "Not exclusively left-to-right readers/writers")}





#' Make an author header
#' sksks
#' @export
MakeAuthorHeader<-function(){
  ReplicationProjectTools::GetLabNames()

  labs = data.frame(Lab = LabNames, Node = Nodes)
  labs %>% arrange(Lab) -> labs
  LabNames = labs$Lab
  Nodes = labs$Node
  AuthorHeader = list()

AuthorLists = map_chr(Nodes, function(x)
  GetNodeFiles(file.path(getwd(), 'data/'), x)[grepl(GetNodeFiles(file.path(getwd(), 'data/'), x), pattern = 'author')])

for (i in 1:length(LabNames)) {
  AuthorList = AuthorLists[i]
  authors = readxl::read_excel(AuthorList, col_names = FALSE)
  names(authors) =  c("var", glue("a{seq(1,length(authors)-1)}"))
  authors %>% filter(var == "Last Name:") %>% pull(a1) -> LabNames[i]


  if((dim(authors)[2] - 1) >= 1){
    authors %>% pull(a1) -> a1
    glue("{ifelse(is.na(a1[1]) ,'',a1[1])} {ifelse(is.na(a1[2]),'',a1[2])} {ifelse(is.na(a1[3]) ,'',a1[3])} ({ifelse(is.na(a1[4]) ,'',a1[4])})") -> a1
  } else {a1 = ''}

  if((dim(authors)[2] - 1) >= 2){
    authors %>% pull(a2) -> a2
    glue("{ifelse(is.na(a2[1]) ,'',a2[1])} {ifelse(is.na(a2[2]),'',a2[2])} {ifelse(is.na(a2[3]) ,'',a2[3])} ({ifelse(is.na(a2[4]) ,'',a2[4])})") -> a2
  } else {a2 = ''}

  if((dim(authors)[2] - 1) >= 3){
    authors %>% pull(a3) -> a3
    glue("{ifelse(is.na(a3[1]) ,'',a3[1])} {ifelse(is.na(a3[2]),'',a3[2])} {ifelse(is.na(a3[3]) ,'',a3[3])} ({ifelse(is.na(a3[4]) ,'',a3[4])})") -> a3
  } else {a3 = ''}

  if((dim(authors)[2] - 1) >= 4){
    authors %>% pull(a4) -> a4
    glue("{ifelse(is.na(a4[1]) ,'',a4[1])} {ifelse(is.na(a4[2]),'',a4[2])} {ifelse(is.na(a4[3]) ,'',a4[3])} ({ifelse(is.na(a4[4]) ,'',a4[4])})") -> a4
  } else {a4 = ''}

  if((dim(authors)[2] - 1) >= 5){
    authors %>% pull(a5) -> a5
    glue("{ifelse(is.na(a5[1]) ,'',a5[1])} {ifelse(is.na(a5[2]),'',a5[2])} {ifelse(is.na(a5[3]) ,'',a5[3])} ({ifelse(is.na(a5[4]) ,'',a5[4])})") -> a5
  } else {a5 = ''}

  if((dim(authors)[2] - 1) >= 6){cat(LabNames[i])}


  AuthorHeader[[i]] = ''
  AuthorHeader[[i]]["a1"] = a1
  AuthorHeader[[i]]["a2"] = a2
  AuthorHeader[[i]]["a3"] = a3
  AuthorHeader[[i]]["a4"] = a4
  AuthorHeader[[i]]["a5"] = a5
}

return(AuthorHeader)

}
